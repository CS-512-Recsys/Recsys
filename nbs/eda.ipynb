{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dc1d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from argparse import Namespace\n",
    "from joblib import dump, load\n",
    "base_dir = Path('/Users/vinay/Projects/Recsys')\n",
    "if not base_dir:\n",
    "    base_dir = Path(os.getcwd())\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_dir = base_dir/'data'/'archive'\n",
    "store_dir = base_dir/'artifacts'\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "522a8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir/'full_rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1048e7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>8507</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004-09-10 03:13:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1</td>\n",
       "      <td>8636</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2005-04-02 23:44:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>8690</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1</td>\n",
       "      <td>8961</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:47:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1</td>\n",
       "      <td>31696</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:49:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating            timestamp\n",
       "0         1        2     3.5  2005-04-02 23:53:47\n",
       "1         1       29     3.5  2005-04-02 23:31:16\n",
       "2         1       32     3.5  2005-04-02 23:33:39\n",
       "3         1       47     3.5  2005-04-02 23:32:07\n",
       "4         1       50     3.5  2005-04-02 23:29:40\n",
       "..      ...      ...     ...                  ...\n",
       "170       1     8507     5.0  2004-09-10 03:13:47\n",
       "171       1     8636     4.5  2005-04-02 23:44:53\n",
       "172       1     8690     3.5  2005-04-02 23:33:15\n",
       "173       1     8961     4.0  2005-04-02 23:47:09\n",
       "174       1    31696     4.0  2005-04-02 23:49:08\n",
       "\n",
       "[175 rows x 4 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a sample df\n",
    "\n",
    "df[df['userId'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a992ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_sz(df,sz=10000):\n",
    "    all_users = sorted(list(set(df['userId'])))\n",
    "    data = []\n",
    "    start = 0\n",
    "    for user in tqdm(all_users):\n",
    "        temp = df[df['userId'] == user]\n",
    "        end = start+len(temp)\n",
    "        temp = copy.deepcopy(temp.reindex(range(start,end)))\n",
    "        start = end\n",
    "        data.append(temp)\n",
    "        if end > sz:\n",
    "            break\n",
    "    return pd.concat(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4f707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9602a0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 90/138493 [00:01<31:08, 74.07it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_df = reduce_sz(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "45d6f8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▊                                   | 6742/138493 [01:28<28:56, 75.85it/s]\n"
     ]
    }
   ],
   "source": [
    "part_df = reduce_sz(df,sz=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d050b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(data_dir/'sample_rating.csv',index=False)\n",
    "part_df.to_csv(data_dir/'partial_rating.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba6709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40e736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3dd66c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7dce4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter,defaultdict\n",
    "user_freq_dict = Counter(df['userId'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fd0f7",
   "metadata": {},
   "source": [
    "## Notes/Observations\n",
    "\n",
    "- We have 20M `user-rating` data from 1995 to 2015.\n",
    "- To avoid `cold-start` problem I choose to split each user data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70572ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000026e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.525529e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.051989e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating\n",
       "count  2.000026e+07\n",
       "mean   3.525529e+00\n",
       "std    1.051989e+00\n",
       "min    5.000000e-01\n",
       "25%    3.000000e+00\n",
       "50%    3.500000e+00\n",
       "75%    4.000000e+00\n",
       "max    5.000000e+00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rating']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84486c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 144.4135299257002, 9254)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_freq = pd.Series(user_freq_dict.values())\n",
    "user_freq.min(),user_freq.mean(),user_freq.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d127d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abab6a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4182421</th>\n",
       "      <td>28507</td>\n",
       "      <td>1176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1995-01-09 11:46:44</td>\n",
       "      <td>1995-01-09 11:46:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950979</th>\n",
       "      <td>131160</td>\n",
       "      <td>1079</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1995-01-09 11:46:49</td>\n",
       "      <td>1995-01-09 11:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950936</th>\n",
       "      <td>131160</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1995-01-09 11:46:49</td>\n",
       "      <td>1995-01-09 11:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950930</th>\n",
       "      <td>131160</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1995-01-09 11:46:49</td>\n",
       "      <td>1995-01-09 11:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12341178</th>\n",
       "      <td>85252</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-01-29 00:00:00</td>\n",
       "      <td>1996-01-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819902</th>\n",
       "      <td>53930</td>\n",
       "      <td>118706</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 06:00:51</td>\n",
       "      <td>2015-03-31 06:00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508834</th>\n",
       "      <td>16978</td>\n",
       "      <td>2093</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 06:03:17</td>\n",
       "      <td>2015-03-31 06:03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12898546</th>\n",
       "      <td>89081</td>\n",
       "      <td>55232</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 06:11:26</td>\n",
       "      <td>2015-03-31 06:11:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12898527</th>\n",
       "      <td>89081</td>\n",
       "      <td>52458</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-03-31 06:11:28</td>\n",
       "      <td>2015-03-31 06:11:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12675921</th>\n",
       "      <td>87586</td>\n",
       "      <td>7151</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 06:40:02</td>\n",
       "      <td>2015-03-31 06:40:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000263 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating            timestamp                date\n",
       "4182421    28507     1176     4.0  1995-01-09 11:46:44 1995-01-09 11:46:44\n",
       "18950979  131160     1079     3.0  1995-01-09 11:46:49 1995-01-09 11:46:49\n",
       "18950936  131160       47     5.0  1995-01-09 11:46:49 1995-01-09 11:46:49\n",
       "18950930  131160       21     3.0  1995-01-09 11:46:49 1995-01-09 11:46:49\n",
       "12341178   85252       45     3.0  1996-01-29 00:00:00 1996-01-29 00:00:00\n",
       "...          ...      ...     ...                  ...                 ...\n",
       "7819902    53930   118706     3.5  2015-03-31 06:00:51 2015-03-31 06:00:51\n",
       "2508834    16978     2093     3.5  2015-03-31 06:03:17 2015-03-31 06:03:17\n",
       "12898546   89081    55232     3.5  2015-03-31 06:11:26 2015-03-31 06:11:26\n",
       "12898527   89081    52458     4.0  2015-03-31 06:11:28 2015-03-31 06:11:28\n",
       "12675921   87586     7151     3.5  2015-03-31 06:40:02 2015-03-31 06:40:02\n",
       "\n",
       "[20000263 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da493cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>8507</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004-09-10 03:13:47</td>\n",
       "      <td>2004-09-10 03:13:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1</td>\n",
       "      <td>8636</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2005-04-02 23:44:53</td>\n",
       "      <td>2005-04-02 23:44:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>8690</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:15</td>\n",
       "      <td>2005-04-02 23:33:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1</td>\n",
       "      <td>8961</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:47:09</td>\n",
       "      <td>2005-04-02 23:47:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1</td>\n",
       "      <td>31696</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:49:08</td>\n",
       "      <td>2005-04-02 23:49:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating            timestamp                date\n",
       "0         1        2     3.5  2005-04-02 23:53:47 2005-04-02 23:53:47\n",
       "1         1       29     3.5  2005-04-02 23:31:16 2005-04-02 23:31:16\n",
       "2         1       32     3.5  2005-04-02 23:33:39 2005-04-02 23:33:39\n",
       "3         1       47     3.5  2005-04-02 23:32:07 2005-04-02 23:32:07\n",
       "4         1       50     3.5  2005-04-02 23:29:40 2005-04-02 23:29:40\n",
       "..      ...      ...     ...                  ...                 ...\n",
       "170       1     8507     5.0  2004-09-10 03:13:47 2004-09-10 03:13:47\n",
       "171       1     8636     4.5  2005-04-02 23:44:53 2005-04-02 23:44:53\n",
       "172       1     8690     3.5  2005-04-02 23:33:15 2005-04-02 23:33:15\n",
       "173       1     8961     4.0  2005-04-02 23:47:09 2005-04-02 23:47:09\n",
       "174       1    31696     4.0  2005-04-02 23:49:08 2005-04-02 23:49:08\n",
       "\n",
       "[175 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = df[df['userId'] == 1]\n",
    "sz = len(t)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80b1d549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 9, 8]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = slice(0,3)\n",
    "l = [0,9,8,7,6,6]\n",
    "l[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "057fc722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5872032</th>\n",
       "      <td>40421</td>\n",
       "      <td>2087</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2008-10-28 13:10:55</td>\n",
       "      <td>2008-10-28 13:10:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15384869</th>\n",
       "      <td>106410</td>\n",
       "      <td>56174</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2008-06-03 13:38:21</td>\n",
       "      <td>2008-06-03 13:38:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867873</th>\n",
       "      <td>68189</td>\n",
       "      <td>2719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1999-10-16 23:39:10</td>\n",
       "      <td>1999-10-16 23:39:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12561962</th>\n",
       "      <td>86773</td>\n",
       "      <td>2826</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-02-22 11:35:30</td>\n",
       "      <td>2013-02-22 11:35:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19092459</th>\n",
       "      <td>132069</td>\n",
       "      <td>2710</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-08-20 03:31:17</td>\n",
       "      <td>2000-08-20 03:31:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19743114</th>\n",
       "      <td>136694</td>\n",
       "      <td>231</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2004-11-12 13:50:08</td>\n",
       "      <td>2004-11-12 13:50:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14106139</th>\n",
       "      <td>97434</td>\n",
       "      <td>5954</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2007-04-22 15:57:28</td>\n",
       "      <td>2007-04-22 15:57:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696389</th>\n",
       "      <td>52988</td>\n",
       "      <td>500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-06-10 15:02:20</td>\n",
       "      <td>1996-06-10 15:02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709984</th>\n",
       "      <td>11555</td>\n",
       "      <td>110</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2001-10-14 16:16:29</td>\n",
       "      <td>2001-10-14 16:16:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473142</th>\n",
       "      <td>23662</td>\n",
       "      <td>3763</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-11-19 17:35:14</td>\n",
       "      <td>2000-11-19 17:35:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating            timestamp                date\n",
       "5872032    40421     2087     4.5  2008-10-28 13:10:55 2008-10-28 13:10:55\n",
       "15384869  106410    56174     3.5  2008-06-03 13:38:21 2008-06-03 13:38:21\n",
       "9867873    68189     2719     1.0  1999-10-16 23:39:10 1999-10-16 23:39:10\n",
       "12561962   86773     2826     3.0  2013-02-22 11:35:30 2013-02-22 11:35:30\n",
       "19092459  132069     2710     5.0  2000-08-20 03:31:17 2000-08-20 03:31:17\n",
       "19743114  136694      231     4.0  2004-11-12 13:50:08 2004-11-12 13:50:08\n",
       "14106139   97434     5954     3.0  2007-04-22 15:57:28 2007-04-22 15:57:28\n",
       "7696389    52988      500     3.0  1996-06-10 15:02:20 1996-06-10 15:02:20\n",
       "1709984    11555      110     5.0  2001-10-14 16:16:29 2001-10-14 16:16:29\n",
       "3473142    23662     3763     4.0  2000-11-19 17:35:14 2000-11-19 17:35:14"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = df.sample(frac=1,ran)\n",
    "t[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b4b06d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40421, 106410, 68189]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[a]['userId'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d5f58004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(data_dir/'full_rating.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a4cc8947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:33:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:35:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  userId  movieId  rating            timestamp\n",
       "0      0       1        2     3.5  2005-04-02 23:53:47\n",
       "1      9       1      260     4.0  2005-04-02 23:33:46\n",
       "2      8       1      253     4.0  2005-04-02 23:35:40"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[0,9,8]].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685bb1e",
   "metadata": {},
   "source": [
    "## Creating and storing the data-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909c9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "global seed \n",
    "import random\n",
    "seed = 0\n",
    "def set_seeds(seed=0):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # multi-GPU\n",
    "set_seeds(seed)\n",
    "    \n",
    "def get_data(data_dir,split:list,mode,data_type,save_to_disk=False):\n",
    "    #split = [0.6,0.5]\n",
    "    #mode = 'random' or 'seq_aware'\n",
    "    trn,vld,tst = defaultdict(list),defaultdict(list),defaultdict(list)\n",
    "    df = pd.read_csv(data_dir/(data_type+'_'+'rating.csv'))\n",
    "    #df = df.sample(frac=1,random_state=seed)\n",
    "    perm = random.sample(range(len(df)),len(df))\n",
    "    df = df.iloc[perm].reset_index()\n",
    "    df['date'] = pd.to_datetime(df['timestamp'])\n",
    "    user_ids = set(df['userId'])\n",
    "    for user in tqdm(user_ids):\n",
    "        tmp = df[df['userId'] == user]\n",
    "        if split == 'seq_aware':\n",
    "            tmp = tmp.sort_values(by='date')\n",
    "        sz = len(tmp)\n",
    "        #splitting-ids\n",
    "        t,v = int(split[0]*sz),int(split[0]*sz)+int((sz-int(split[0]*sz))*split[-1])\n",
    "        trn_ids,vld_ids,tst_ids = slice(0,t),slice(t,v),slice(v,sz)\n",
    "        \n",
    "        trn['user_id'].extend(tmp[trn_ids]['userId'].tolist())\n",
    "        trn['rating'].extend(tmp[trn_ids]['rating'].tolist())\n",
    "        trn['movie_id'].extend(tmp[trn_ids]['movieId'].tolist())\n",
    "        \n",
    "        \n",
    "        vld['user_id'].extend(tmp[vld_ids]['userId'].tolist())\n",
    "        vld['rating'].extend(tmp[vld_ids]['rating'].tolist())\n",
    "        vld['movie_id'].extend(tmp[vld_ids]['movieId'].tolist())\n",
    "        \n",
    "        tst['user_id'].extend(tmp[tst_ids]['userId'].tolist())\n",
    "        tst['rating'].extend(tmp[tst_ids]['rating'].tolist())\n",
    "        tst['movie_id'].extend(tmp[tst_ids]['movieId'].tolist())\n",
    "    trn,vld,tst = pd.DataFrame(trn),pd.DataFrame(vld),pd.DataFrame(tst)\n",
    "    if save_to_disk:\n",
    "        trn.to_csv(data_dir/(data_type+'_'+mode+'_trn.csv'))\n",
    "        vld.to_csv(data_dir/(data_type+'_'+mode+'_vld.csv'))\n",
    "        tst.to_csv(data_dir/(data_type+'_'+mode+'_tst.csv'))\n",
    "    return trn,vld,tst\n",
    "        \n",
    "    \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e052b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b2e076e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 91/91 [00:00<00:00, 1643.87it/s]\n"
     ]
    }
   ],
   "source": [
    "t,v,tt = get_data(data_dir,[0.6,0.5],'random','sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8aa8d084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(t['user_id'])== set(tt['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7e9c651a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30165289256198347"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tt['movie_id'])-set(t['movie_id']))/len(set(tt['movie_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f197f3",
   "metadata": {},
   "source": [
    "We may be not able to use all this data.Let's make smaller data-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "10fb2077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 91/91 [00:00<00:00, 1564.59it/s]\n"
     ]
    }
   ],
   "source": [
    "data_type = 'sample'\n",
    "split = 'random'\n",
    "t,v,tt = get_data(data_dir,[0.6,0.5],split,data_type,save_to_disk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "48e2ad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 6743/6743 [00:07<00:00, 921.97it/s]\n"
     ]
    }
   ],
   "source": [
    "data_type = 'partial'\n",
    "t,v,tt = get_data(data_dir,[0.6,0.5],split,data_type,save_to_disk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4d4e2f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6743, 12649)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(t['user_id'])),len(set(t['movie_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7f72d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(t['user_id']) == set(tt['user_id'])\n",
    "assert set(t['movie_id']) != set(tt['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9e65262d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07414910858995137"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tt['movie_id'])-set(t['movie_id']))/len(set(tt['movie_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28efdcfa",
   "metadata": {},
   "source": [
    "Note that 7 percent of movies are not there in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e8e086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e36544d",
   "metadata": {},
   "source": [
    "## Testing on dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "329c0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecsysDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df,usr_dict=None,mov_dict=None):\n",
    "        self.df = df\n",
    "        self.usr_dict = usr_dict\n",
    "        self.mov_dict = mov_dict\n",
    "    def __getitem__(self,index):\n",
    "        if self.usr_dict and self.mov_dict:\n",
    "            return [self.usr_dict[int(self.df.iloc[index]['user_id'])],self.mov_dict[int(self.df.iloc[index]['movie_id'])]],self.df.iloc[index]['rating']\n",
    "        else:\n",
    "            return [int(self.df.iloc[index]['user_id']-1),int(self.df.iloc[index]['movie_id']-1)],self.df.iloc[index]['rating']\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "70d3a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame({'user_id':[1,2,3,2,2,3,2,2],'movie_id':[1,2,3,3,3,2,1,1],'rating':[2.0,1.0,4.0,5.0,1.3,3.5,3.0,4.5]})\n",
    "trn_ids = random.sample(range(8),4,)\n",
    "valid_ids = [i for i in range(8) if i not in trn_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c4ee10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4a04effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_trn,sample_vld = copy.deepcopy(sample.iloc[trn_ids].reset_index()),copy.deepcopy(sample.iloc[valid_ids].reset_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8c92f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vld = RecsysDataset(sample_vld)\n",
    "sample_trn = RecsysDataset(sample_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1884bdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 0], 2.0)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_vld[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3adc587e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "185b4237",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(sample_trn, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0dacf36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(sample_vld, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9dd3f8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user:tensor([1, 2]),item:tensor([2, 1]) and rating:tensor([1.3000, 3.5000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for u,r in train_loader:\n",
    "    #user,item = u\n",
    "    print(f'user:{u[0]},item:{u[-1]} and rating:{r}')\n",
    "    #print(u)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f82468c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5350,  0.0490, -1.6023, -1.3283, -2.2907],\n",
       "        [ 1.6614,  1.2145, -2.7802,  0.4113, -0.2785],\n",
       "        [ 0.2881, -0.2528, -0.9804, -0.6115, -2.3585]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(3, 5)\n",
    "a = torch.tensor([1,2,0])\n",
    "embedding(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4cec7b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-torch.clip(torch.tensor(9),min=0.0,max=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00730779",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c535034",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self,user_sz,item_sz,embd_sz,dropout_fac,min_r=0.0,max_r=5.0,alpha=0.5,with_variable_alpha=False):\n",
    "        super().__init__()\n",
    "        self.dropout_fac = dropout_fac\n",
    "        self.user_embd_mtrx = nn.Embedding(user_sz,embd_sz)\n",
    "        self.item_embd_mtrx = nn.Embedding(item_sz,embd_sz)\n",
    "        #bias = torch.zeros(size=(user_sz, 1), requires_grad=True)\n",
    "        self.h =  nn.Linear(embd_sz,1)\n",
    "        self.fst_lyr = nn.Linear(embd_sz*2,embd_sz)\n",
    "        self.snd_lyr = nn.Linear(embd_sz,embd_sz//2)\n",
    "        self.thrd_lyr = nn.Linear(embd_sz//2,embd_sz//4)\n",
    "        self.out_lyr = nn.Linear(embd_sz//4,1)\n",
    "        self.alpha = torch.tensor(alpha)\n",
    "        self.min_r,self.max_r = min_r,max_r\n",
    "        if with_variable_alpha:\n",
    "            self.alpha = torch.tensor(alpha,requires_grad=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        user_emd = self.user_embd_mtrx(x[0])\n",
    "        item_emd = self.item_embd_mtrx(x[-1])\n",
    "        #hadamard-product\n",
    "        gmf = user_emd*item_emd\n",
    "        gmf = self.h(gmf)\n",
    "        \n",
    "        mlp = torch.cat([user_emd,item_emd],dim=-1)\n",
    "        mlp = self.out_lyr(self.thrd_lyr(self.snd_lyr(F.dropout(self.fst_lyr(mlp),p=self.dropout_fac))))\n",
    "        fac = torch.clip(self.alpha,min=0.0,max=1.0)\n",
    "        out = fac*gmf+ (1-fac)*mlp\n",
    "        out = torch.clip(out,min=self.min_r,max=self.max_r)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "257ee1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user:tensor([1, 1]),item:tensor([2, 0]) and rating:tensor([1.3000, 4.5000], dtype=torch.float64)\n",
      "output of the network=> out:tensor([[0.],\n",
      "        [0.]], grad_fn=<ClampBackward1>),shape:torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "#does it work\n",
    "model = NCF(3,3,4,0.5)\n",
    "for u,r in train_loader:\n",
    "    #user,item = u\n",
    "    print(f'user:{u[0]},item:{u[-1]} and rating:{r}')\n",
    "    #print(u)\n",
    "    out = model(u)\n",
    "    print(f'output of the network=> out:{out},shape:{out.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae1145",
   "metadata": {},
   "source": [
    "## Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5442585",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, device,loss_fn=None, optimizer=None, scheduler=None,artifacts_loc=None,exp_tracker=None):\n",
    "\n",
    "        # Set params\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.store_loc = artifacts_loc\n",
    "        self.exp_tracker = exp_tracker\n",
    "\n",
    "    def train_step(self, dataloader):\n",
    "        \"\"\"Train step.\"\"\"\n",
    "        # Set model to train mode\n",
    "        self.model.train()\n",
    "        loss = 0.0\n",
    "\n",
    "        # Iterate over train batches\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            #batch = [item.to(self.device) for item in batch]  # Set device\n",
    "            inputs,targets = batch\n",
    "            inputs = [item.to(self.device) for item in inputs]\n",
    "            targets = targets.to(self.device)\n",
    "            #inputs, targets = batch[:-1], batch[-1]\n",
    "            #import pdb;pdb.set_trace()\n",
    "            self.optimizer.zero_grad()  # Reset gradients\n",
    "            z = self.model(inputs)  # Forward pass\n",
    "            targets = targets.reshape(z.shape)\n",
    "            J = self.loss_fn(z.float(), targets.float())  # Define loss\n",
    "            J.backward()  # Backward pass\n",
    "            self.optimizer.step()  # Update weights\n",
    "\n",
    "            # Cumulative Metrics\n",
    "            loss += (J.detach().item() - loss) / (i + 1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def eval_step(self, dataloader):\n",
    "        \"\"\"Validation or test step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        y_trues, y_probs = [], []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                inputs,y_true = batch\n",
    "                inputs = [item.to(self.device) for item in inputs]\n",
    "                y_true = y_true.to(self.device).float()\n",
    "\n",
    "                # Step\n",
    "                z = self.model(inputs).float()  # Forward pass\n",
    "                y_true = y_true.reshape(z.shape)\n",
    "                J = self.loss_fn(z, y_true).item()\n",
    "\n",
    "                # Cumulative Metrics\n",
    "                loss += (J - loss) / (i + 1)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = z.cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "                y_trues.extend(y_true.cpu().numpy())\n",
    "\n",
    "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
    "\n",
    "    def predict_step(self, dataloader):\n",
    "        \"\"\"Prediction step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        y_probs = []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Forward pass w/ inputs\n",
    "                inputs, targets = batch\n",
    "                z = self.model(inputs).float()\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = z.cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "\n",
    "        return np.vstack(y_probs)\n",
    "    \n",
    "    def train(self, num_epochs, patience, train_dataloader, val_dataloader, \n",
    "              tolerance=1e-5):\n",
    "        best_val_loss = np.inf\n",
    "        training_stats = defaultdict(list)\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            # Steps\n",
    "            train_loss = self.train_step(dataloader=train_dataloader)\n",
    "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
    "            #store stats\n",
    "            training_stats['epoch'].append(epoch)\n",
    "            training_stats['train_loss'].append(train_loss)\n",
    "            training_stats['val_loss'].append(val_loss)\n",
    "            #log-stats\n",
    "            if self.exp_tracker == 'wandb':\n",
    "                log_metrics = {'epoch':epoch,'train_loss':train_loss,'val_loss':val_loss}\n",
    "                wandb.log(log_metrics,step=epoch)\n",
    "            \n",
    "            self.scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss - tolerance:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = self.model\n",
    "                _patience = patience  # reset _patience\n",
    "            else:\n",
    "                _patience -= 1\n",
    "            if not _patience:  # 0\n",
    "                print(\"Stopping early!\")\n",
    "                break\n",
    "\n",
    "            # Tracking\n",
    "            #mlflow.log_metrics({\"train_loss\": train_loss, \"val_loss\": val_loss}, step=epoch)\n",
    "\n",
    "            # Logging\n",
    "            if epoch%10 == 0:\n",
    "                print(\n",
    "                    f\"Epoch: {epoch+1} | \"\n",
    "                    f\"train_loss: {train_loss:.5f}, \"\n",
    "                    f\"val_loss: {val_loss:.5f}, \"\n",
    "                    f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
    "                    f\"_patience: {_patience}\"\n",
    "                )\n",
    "        if self.store_loc:\n",
    "            pd.DataFrame(training_stats).to_csv(self.store_loc/'training_stats.csv',index=False)\n",
    "        return best_model, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "db3a768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=5)\n",
    "\n",
    "trainer = Trainer(model,'cpu',loss_fn,optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cc6b0ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 14.79750, val_loss: 7.50000, lr: 1.00E-03, _patience: 10\n",
      "Stopping early!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(NCF(\n",
       "   (user_embd_mtrx): Embedding(3, 4)\n",
       "   (item_embd_mtrx): Embedding(3, 4)\n",
       "   (h): Linear(in_features=4, out_features=1, bias=True)\n",
       "   (fst_lyr): Linear(in_features=8, out_features=4, bias=True)\n",
       "   (snd_lyr): Linear(in_features=4, out_features=2, bias=True)\n",
       "   (thrd_lyr): Linear(in_features=2, out_features=1, bias=True)\n",
       "   (out_lyr): Linear(in_features=1, out_features=1, bias=True)\n",
       " ),\n",
       " 7.5)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(100,10,train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362199a3",
   "metadata": {},
   "source": [
    "The code -> Network+trainingloop works. Let's write experiment tracking system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "cfec51d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_random_tst.csv',\n",
       " 'partial_rating.csv',\n",
       " 'full_rating.csv',\n",
       " 'partial_random_trn.csv',\n",
       " 'sample_random_vld.csv',\n",
       " 'tag.csv',\n",
       " 'partial_random_tst.csv',\n",
       " 'sample_rating.csv',\n",
       " 'genome_scores.csv',\n",
       " 'sample_random_trn.csv',\n",
       " 'partial_random_vld.csv',\n",
       " 'genome_tags.csv',\n",
       " 'link.csv',\n",
       " 'movie.csv']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90f5217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mode = 'train','inference'\n",
    "#data_type = 'sample','full','partial'\n",
    "\n",
    "args = Namespace(\n",
    "    exp_tracker = 'wandb',\n",
    "    base_dir = '/Users/vinay/Projects/Recsys',\n",
    "    model_path = '',\n",
    "    trail_id = 0,\n",
    "    dataset = 'movielens',\n",
    "    mode = 'train',\n",
    "    on = ['trn','vld','tst'],\n",
    "    alpha=0.5,\n",
    "    with_variable_alpha=False,\n",
    "    data_type = 'sample',\n",
    "    split_type = 'random',\n",
    "    split = [0.6,0.5],\n",
    "    embd_sz = 10,\n",
    "    batch_size=64, \n",
    "    dropout_p=0.5,\n",
    "    lr=2e-4,\n",
    "    num_epochs=100,\n",
    "    patience=10\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82aa1e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_tracker': 'wandb',\n",
       " 'base_dir': '/Users/vinay/Projects/Recsys',\n",
       " 'model_path': '',\n",
       " 'trail_id': 0,\n",
       " 'dataset': 'movielens',\n",
       " 'mode': 'train',\n",
       " 'on': ['trn', 'vld', 'tst'],\n",
       " 'alpha': 0.5,\n",
       " 'with_variable_alpha': False,\n",
       " 'data_type': 'sample',\n",
       " 'split_type': 'random',\n",
       " 'split': [0.6, 0.5],\n",
       " 'embd_sz': 10,\n",
       " 'batch_size': 64,\n",
       " 'dropout_p': 0.5,\n",
       " 'lr': 0.0002,\n",
       " 'num_epochs': 100,\n",
       " 'patience': 10}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "75e13d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample_seq_aware_trn.csv'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity testing\n",
    "\n",
    "set(t['movie_id']) != set(tt['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df31178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args):\n",
    "    #main function that handles everything.\n",
    "    config_dict = vars(args)\n",
    "    if args.exp_tracker == 'wandb':\n",
    "        wandb.init(project=f\"{args.trail_id}_{args.dataset}_{args.data_type}\",config=config_dict)\n",
    "        \n",
    "    base_dir = Path(args.base_dir)\n",
    "    if not args.base_dir:\n",
    "        base_dir = Path(os.getcwd())\n",
    "        \n",
    "    if args.dataset == 'movielens':\n",
    "        data_dir = base_dir/'data'/'archive'\n",
    "    else:\n",
    "        Print('Unknown dataset')\n",
    "        exit()\n",
    " \n",
    "    store_dir = base_dir/'artifacts'\n",
    "    base_dir = args.base_dir\n",
    "    os.makedirs(store_dir,exist_ok=True)\n",
    "    \n",
    "    #Check if all the necessary data is already there\n",
    "    is_data_premade = True\n",
    "    for d_type in args.on:\n",
    "        file_name = args.data_type+'_'+args.split_type+'_'+d_type+'.csv'\n",
    "        if file_name not in os.listdir(data_dir):\n",
    "            is_data_premade=False\n",
    "   \n",
    "    #load the dataset\n",
    "    df = pd.read_csv(data_dir/(args.data_type+'_'+'rating.csv'))\n",
    "    mov_dict = dict(zip(sorted(set(df['movieId'])),range(len(sorted(set(df['movieId']))))))\n",
    "    usr_dict = dict(zip(sorted(set(df['userId'])),range(len(sorted(set(df['userId']))))))\n",
    "        \n",
    "    if not is_data_premade:\n",
    "        pass\n",
    "        #get-data\n",
    "        #?\n",
    "        #trn_df,vld_df,tst_df = get_data()\n",
    "    else:\n",
    "        #load the csv's\n",
    "        trn_file= args.data_type+'_'+args.split_type+'_'+'trn'+'.csv'\n",
    "        vld_file = args.data_type+'_'+args.split_type+'_'+'vld'+'.csv'\n",
    "        tst_file = args.data_type+'_'+args.split_type+'_'+'tst'+'.csv'\n",
    "        trn_df,vld_df,tst_df = pd.read_csv(data_dir/trn_file),pd.read_csv(data_dir/vld_file),pd.read_csv(data_dir/tst_file)\n",
    "        \n",
    "    train_artifacts_loc = store_dir/(str(args.trail_id)+'_'+args.dataset+'_'+args.data_type)\n",
    "    exp_tracker = args.exp_tracker\n",
    "    if args.mode == 'train':\n",
    "         \n",
    "        #train-from scratch\n",
    "        trn = RecsysDataset(trn_df,usr_dict,mov_dict)\n",
    "        vld = RecsysDataset(vld_df,usr_dict,mov_dict)\n",
    "        tst = RecsysDataset(tst_df,usr_dict,mov_dict)\n",
    "        \n",
    "        trn_dl,vld_dl,tst_dl = dl(trn, batch_size=args.batch_size, shuffle=True),dl(vld, batch_size=args.batch_size),dl(tst, batch_size=args.batch_size)\n",
    "        \n",
    "        #get model\n",
    "        emb_len_usr = len(set(df['userId']))\n",
    "        emb_len_itm = len(set(df['movieId']))\n",
    "        model = NCF(emb_len_usr,emb_len_itm,args.embd_sz,args.dropout_p,alpha=args.alpha,with_variable_alpha=args.with_variable_alpha)\n",
    "        \n",
    "        device = 'cpu'\n",
    "        loss_fn = nn.MSELoss()\n",
    "        # Define optimizer & scheduler\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=5)\n",
    "        \n",
    "        \n",
    "        os.makedirs(train_artifacts_loc,exist_ok=True)\n",
    "        \n",
    "        #train\n",
    "        trainer = Trainer(model,'cpu',loss_fn,optimizer,scheduler,artifacts_loc=train_artifacts_loc,exp_tracker=exp_tracker)\n",
    "        best_model, best_val_loss = trainer.train(args.num_epochs,args.patience,trn_dl,vld_dl)\n",
    "        #save the model\n",
    "        PATH = train_artifacts_loc/'model.pth'\n",
    "        torch.save(best_model.state_dict(), PATH)\n",
    "        \n",
    "        test_ratings = tst_df['rating']\n",
    "        #loss, np.vstack(y_trues), np.vstack(y_probs)\n",
    "        tst_loss,y_trues,y_predict = trainer.eval_step(tst_dl)\n",
    "        test_rslts = pd.DataFrame({'y_true':y_trues.squeeze(),'y_pred':y_predict.squeeze()},index=range(len(y_trues)))\n",
    "        \n",
    "        #save test predictions\n",
    "        test_rslts.to_csv(str(train_artifacts_loc/('inference'+'_'+args.split_type+'_tst'+'.csv')))\n",
    "        dump(args,train_artifacts_loc/'args.joblib')\n",
    "        \n",
    "    if args.mode == 'inference':\n",
    "        losses = {}\n",
    "        for split_type in args.on:\n",
    "            #'trn','vld','tst'\n",
    "            if split_type == 'trn':\n",
    "                data = RecsysDataset(trn_df)\n",
    "            elif split_type == 'vld':\n",
    "                data = RecsysDataset(vld_df)\n",
    "            elif split_type == 'tst':\n",
    "                data = RecsysDataset(tst_df)\n",
    "            data_dl = dl(data, batch_size=args.batch_size)\n",
    "            #?load it from the path\n",
    "            dir_loc = store_dir/(str(trail_id)+'_'+dataset+'_'+data_type)\n",
    "            #model  = \n",
    "            trainer = Trainer(model,'cpu',loss_fn,optimizer,scheduler,artifacts_loc=train_artifacts_loc)\n",
    "            tst_loss,y_trues,y_predict = trainer.eval_step(data_dl)\n",
    "            test_rslts = pd.DataFrame({'y_true':y_trues.squeeze(),'y_pred':y_predict})\n",
    "            \n",
    "            losses[split_type] = tst_loss\n",
    "            test_rslts.to_csv(str(dir_loc)/('inference'+'_'+split_type+'.csv'))\n",
    "                \n",
    "     \n",
    "                \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b5df23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1hmb5zyw) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 50165... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">ancient-frost-2</strong>: <a href=\"https://wandb.ai/vin136/0_movielens_sample/runs/1hmb5zyw\" target=\"_blank\">https://wandb.ai/vin136/0_movielens_sample/runs/1hmb5zyw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211127_204835-1hmb5zyw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1hmb5zyw). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/vin136/0_movielens_sample/runs/2frch3tf\" target=\"_blank\">visionary-lion-3</a></strong> to <a href=\"https://wandb.ai/vin136/0_movielens_sample\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                          | 1/100 [00:00<01:32,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 13.95471, val_loss: 14.04778, lr: 2.00E-04, _patience: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▌                                     | 11/100 [00:09<01:18,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | train_loss: 5.04894, val_loss: 4.82705, lr: 2.00E-04, _patience: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▊                                 | 21/100 [00:18<01:09,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | train_loss: 2.72389, val_loss: 2.78317, lr: 2.00E-04, _patience: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████                             | 31/100 [00:27<01:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | train_loss: 2.17387, val_loss: 2.25598, lr: 2.00E-04, _patience: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████▏                        | 41/100 [00:36<00:51,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | train_loss: 1.79190, val_loss: 1.74291, lr: 2.00E-04, _patience: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████▍                    | 51/100 [00:45<00:43,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 | train_loss: 1.56078, val_loss: 1.51700, lr: 2.00E-04, _patience: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████▌                | 61/100 [00:54<00:35,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 | train_loss: 1.34089, val_loss: 1.33083, lr: 2.00E-04, _patience: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████▊            | 71/100 [01:02<00:25,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71 | train_loss: 1.18920, val_loss: 1.14950, lr: 2.00E-04, _patience: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████        | 81/100 [01:11<00:16,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81 | train_loss: 1.10881, val_loss: 1.07645, lr: 2.00E-04, _patience: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████▏   | 91/100 [01:20<00:08,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91 | train_loss: 1.05481, val_loss: 1.02154, lr: 2.00E-04, _patience: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [01:29<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "run(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42d2d7",
   "metadata": {},
   "source": [
    "Above run is on a sample of the dataset(size=10000 rows). We can see that both train and validation losses is going down, thus our implementation is likely correct. We can run the same on our `full` or `partial` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a286443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
